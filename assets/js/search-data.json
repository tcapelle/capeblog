{
  
    
        "post0": {
            "title": "The Devil lives in the details",
            "content": "Yesterday I was refactoring some code to put on our production code base. It is a simple image classifier trained with fastai. In our deployement env we are not including fastai as requirements and rely only on pure pytorch to process the data and make the inferece. (I am waiting to finally be able to install only the fastai vision part, without the NLP dependencies, this is coming soon, probably in fastai 2.3, at least it is in Jeremy&#39;s roadmap). So, I have to make the reading and preprocessing of images as close as possible as fastai Transform pipeline, to get accurate model outputs. . Let&#39;s take a quick look on the preprocessing used for training and there corresponding torch version with the new tensor API as shown here . A simple example . Let&#39;s make a simple classifier on the PETS dataset, for more details this comes from the fastai tutorial . from fastai.vision.all import * set_seed(2021) . . let&#39;s grab the data . path = untar_data(URLs.PETS) files = get_image_files(path/&quot;images&quot;) def label_func(f): return f[0].isupper() dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize((256, 192))) . A learner it is just a wrapper of Dataloaders and the model. We will grab an imagene pretrained resnet18, we don&#39;t really need to train it to illustrate the problem. . learn = cnn_learner(dls, resnet18) . and grab one image (load_image comes from fastai and returns a memory loaded PIL.Image.Image) . fname = files[1] img = load_image(fname) img . learn.predict(fname) . (&#39;False&#39;, tensor(0), tensor([0.9191, 0.0809])) . Let&#39;s understand what is happening under the hood: . and we can call the prediction using fastai predict method, this will apply the same transforms as to the validation set. . create PIL image | Transform the image to pytorch Tensor | Scale values by 255 | Normalize with imagenet stats | . doing this by hand is extracting the preprocessing transforms: . dls.valid.tfms . (#2) [Pipeline: PILBase.create,Pipeline: partial -&gt; Categorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False}] . dls.valid.after_item . Pipeline: Resize -- {&#39;size&#39;: (192, 256), &#39;method&#39;: &#39;crop&#39;, &#39;pad_mode&#39;: &#39;reflection&#39;, &#39;resamples&#39;: (2, 0), &#39;p&#39;: 1.0} -&gt; ToTensor . dls.valid.after_batch . Pipeline: IntToFloatTensor -- {&#39;div&#39;: 255.0, &#39;div_mask&#39;: 1} -&gt; Normalize -- {&#39;mean&#39;: tensor([[[[0.4850]], [[0.4560]], [[0.4060]]]]), &#39;std&#39;: tensor([[[[0.2290]], [[0.2240]], [[0.2250]]]]), &#39;axes&#39;: (0, 2, 3)} . Let&#39;s put all transforms together on a fastcore Pipeline . preprocess = Pipeline([Transform(PILImage.create), Resize((256,192)), ToTensor, IntToFloatTensor, Normalize.from_stats(*imagenet_stats)]) . we can then preprocess the image: . tfm_img = preprocess(fname) tfm_img.shape . torch.Size([1, 3, 256, 192]) . and we get the exact same predictions as before . with torch.no_grad(): preds = model(tfm_img).softmax(1) preds . tensor([[0.9191, 0.0809]]) . Using torchvision preprocessing . Now let&#39;s try to replace fastai transforms with torchvision . import PIL import torchvision.transforms as T . pil_image = load_image(fname) pil_image . type(pil_image) . PIL.Image.Image . let&#39;s first resize the image, we can do this directly over the PIL.Image.Image or using T.Resize that works both on IPIL images or Tensors . resize = T.Resize([256, 192]) res_pil_image = res(pil_image) . we can then use T.ToTensor this will actually scale by 255 and transform to tensor, it is equivalent to both ToTensor + IntToFloatTensor from fastai. . timg = T.ToTensor()(res_pil_image) . then we have to normalize it: . norm = T.Normalize(*imagenet_stats) nimg = norm(timg).unsqueeze(0) . and we get almost and identical results! ouff..... . with torch.no_grad(): preds = model(nimg).softmax(1) preds . tensor([[0.9109, 0.0891]]) . Torchvision new Tensor API . Let&#39;s try this new Tensor based API that torchvision introduced on v0.8 then! . import torchvision.transforms as T from torchvision.io.image import read_image . read_image is pretty neat, it actually read directly the image to a pytorch tensor, so no need for external image libraries. Using this API has many advantages, as one can group the model and part of the preprocessing as whole, and then export to torchscript all togeter: model + preprocessing, as shown in the example here . timg = read_image(str(fname)) # it is sad that it does not support pathlib objects in 2021... . resize = T.Resize([256, 192]) res_timg = res(timg) . we have to scale it, we have a new transform to do this: . scale = T.ConvertImageDtype(torch.float) scaled_timg = scale(res_timg) . norm = T.Normalize(*imagenet_stats) nimg = norm(scaled_timg).unsqueeze(0) . Ok, the results is pretty different... . with torch.no_grad(): preds = model(nimg).softmax(1) preds . tensor([[0.9844, 0.0156]]) . if you trained your model with the old API, reading images using PIL you may find yourself lost as why the models is performing poorly. My classifier was predicting completely the opossite for some images, and that&#39;s why I realized that something was wrong! . Let&#39;s dive what is happening... . Comparing Resizing methods . T.Resize on PIL image vs Tensor Image . We will use fastai&#39;s show_images to make the loading and showing of tensor images easy . resize = T.Resize([256, 192], interpolation=PIL.Image.BILINEAR) . pil_img = load_image(fname) res_pil_img = image2tensor(resize(pil_img)) tensor_img = read_image(str(fname)) res_tensor_img = resize(tensor_img) . show_images([res_pil_img, res_tensor_img], figsize=(10,5), titles=[&#39;PIL&#39;, &#39;Tensor&#39;]) . Let&#39;s zoome and plot . show_images([res_pil_img[:,20:80, 30:100], res_tensor_img[:,20:80, 30:100]], figsize=(10,5), titles=[&#39;PIL&#39;, &#39;Tensor&#39;]) . The PIL image is smoother, it is not necesarily better, but it is different. From my testing, for darker images the PIL reisze has less moire effect (less noise) . Extra: What if I want to use OpenCV? . A popular choice for pilepines that rely on numpy array transforms, as Albumnetation . import cv2 . opencv opens directly an array . img_cv = cv2.imread(str(fname)) res_img_cv = cv2.resize(img_cv, (256,192), interpolation=cv2.INTER_LINEAR) . BGR to RGB, and channel first. . res_img_cv = res_img_cv.transpose((2,0,1))[::-1,:,:].copy() . timg_cv = cast(res_img_cv, TensorImage) timg_cv.shape . torch.Size([3, 192, 256]) . timg_cv[:,20:80, 30:100].show(figsize=(8,8)) . &lt;AxesSubplot:&gt; . pretty bad also... . learn.predict(timg_cv) . (&#39;True&#39;, tensor(1), tensor([0.4923, 0.5077])) . with INTER_AREA flag . This method is closer to PIL image resize, as it has a kernel that smooths the image. . img_cv_area = cv2.imread(str(fname)) img_cv_area = cv2.resize(img_cv_area, (256,192), interpolation=cv2.INTER_AREA) . img_cv_area = img_cv_area.transpose((2,0,1))[::-1,:,:].copy() . timg_cv_area = cast(img_cv_area, TensorImage) . timg_cv_area[:,20:80, 30:100].show(figsize=(8,8)) . &lt;AxesSubplot:&gt; . kinda of better... . learn.predict(timg_cv_area) . (&#39;False&#39;, tensor(0), tensor([0.9602, 0.0398])) . Conclusions . Ideally, deploy the model with the exact same transforms as it was validated. Or at least, check that the preformance does not degrade. I would like to see more consistency between both API in pure pytorch, as the user is pushed to use the new pillow-free pipeline, but results are not consistent. Resize is a fundamental part of the image preprocessing in most user cases. . There is an issue open on the torchvision github about this. | Also one about the difference between PIL and openCV here | . This was pretty frustrating, as it was not obviuos where the model was failing. .",
            "url": "https://tcapelle.github.io/capeblog/pytorch/fastai/2021/02/26/image_resizing.html",
            "relUrl": "/pytorch/fastai/2021/02/26/image_resizing.html",
            "date": " • Feb 26, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://tcapelle.github.io/capeblog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://tcapelle.github.io/capeblog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://tcapelle.github.io/capeblog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}